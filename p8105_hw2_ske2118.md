HW2
================

## ‘Problem 1’

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or case_match function may be useful).

Import dataset and clean up column names. Retain specified columns and
convert entry variable from char to log. Convert route 8-11 to character
variables to match route 1-7.

``` r
subway_df = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1, route2,route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
   mutate(
      route8 = as.character(route8),
      route9 = as.character(route9),
      route10 = as.character(route10),
      route11 = as.character(route11)) |>
  mutate(entry = ifelse(entry == "NO", FALSE, TRUE)) 
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Apply pivot_longer to tidy up route columns.

``` r
subway_df <- subway_df |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "route", 
    names_prefix = "route",
    values_to = "subway_line")
```

This dataset contains variables about the NYC subway lines. Columns
include line, station name, coordinates, route,subway_route, entry,
vending, entrance_type, and ADA accessibility. It has 4270 rows and 10
columns. To clean the data, I first used the janitor step to clean the
column names to use snake case formatting. Then I selected our columns
of interest and changed the entry variable from character to logical.
Then I converted all the routes to character variables so I could apply
pivot-longer to get route1-route11 in rows rather than columns.

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway;
125st Lenox); the distinct function may be useful here.

``` r
subway_df$full_station_name <-
  paste(subway_df$line, subway_df$station_name)
```

There are 465 distinct station names.

How many stations are ADA compliant?

``` r
sum(stations=TRUE, na.rm=TRUE)
```

    ## [1] 1

There are stations that are ADA compliant.

What proportion of station entrances / exits without vending allow
entrance?

``` r
sum(entrances=TRUE, na.rm=TRUE)
```

    ## [1] 1

There are stations entrances/exits without vending that allow entrance.

### Problem 2

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel use reasonable variable names omit rows that do not include
dumpster-specific data round the number of sports balls to the nearest
integer and converts the result to an integer variable (using
as.integer)

``` r
mr_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                            sheet = "Mr. Trash Wheel", range = "A2:N653") |>
  janitor::clean_names() |>
   drop_na(dumpster) |>
  mutate(
    sports_balls = as.integer(round(sports_balls))
    )
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda.

``` r
prof_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                            sheet = "Professor Trash Wheel", range = "A2:M121") |>
  janitor::clean_names() |>
   drop_na(dumpster) 

gwynnda_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
                            sheet = "Gwynnda Trash Wheel", range = "A2:L266") |>
  janitor::clean_names() |>
   drop_na(dumpster) 
```

Combine this with the Mr. Trash Wheel dataset to produce a single tidy
dataset. To keep track of which Trash Wheel is which, you may need to
add an additional variable to both datasets before combining.

``` r
mr_trash_wheel <- mr_trash_wheel |>
  mutate(wheel = "trash_wheel" ,
          year = as.double(year))

prof_trash_wheel<- prof_trash_wheel |>
  mutate(wheel = "prof_trash_wheel", 
          year = as.double(year))

gwynnda_trash_wheel  <- gwynnda_trash_wheel |>
  mutate(wheel = "gwynnda_wheel",
          year = as.double(year))

trash_wheel_tidy <-
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)
```

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in June of 2022?

The number of observations in this dataset are 1033 and key variables
are wheel, dumpster, month, year, date, and volume_cubic_yards. It tells
us interesting data on the various types of trash wheels and the amount
and type of trash they clean.

The total weight of trash collected by Professor Trash Wheel is

246.74 tons total weight of trash.

The total number of cigarette butts collected by Gwynnda in June of 2022

``` r
trash_wheel_tidy_butts <- trash_wheel_tidy |>
  mutate(year = as.numeric(year)) |>
  filter( month == "June", year == 2022)
```

The total number of cigarette butts collected by Gwynnda in June of 2022
1.812^{4} cigarette butts.

### Problem 3

In the first part of this problem, your goal is to create a single,
well-organized dataset with all the information contained in these data
files. To that end: import, clean, tidy, and otherwise wrangle each of
these datasets; check for completeness and correctness across datasets
(e.g. by viewing individual datasets and using anti_join); merge to
create a single, final dataset; and organize this so that variables and
observations are in meaningful orders. Export the result as a CSV in the
directory containing the original datasets.

Using janitor::clean_names() to clean all the column names.

``` r
bakers_df = read_csv("data/bakers.csv") |>
  janitor::clean_names() 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = read_csv("data/bakes.csv",
  na = c("NA", ".", "", "UNKNOWN","Unknown", "N/A")) |>
  janitor::clean_names() 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = read_csv("data/results.csv", skip = 2) |>
  janitor::clean_names() 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers_df = read_csv("data/viewers.csv") |>
  janitor::clean_names() 
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Baker_name in bakers_f is first and last name whereas all other df has
column baker with just first name. Separate this column into first and
last name.

Results_df first two rows are not useful, skip them so the third row
becomes our columns.

We notice that in each of the four datasets there is series so we can
join by that variable and want to make sure it is organized and the same
across all four datasets.

clean bakers_df

``` r
bakers_df <- bakers_df |>
  separate(baker_name, into = c("baker", "baker_last_name"), sep = " ")
```

clean viewers_df

``` r
viewers_df <- viewers_df |>
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series_number",
    names_prefix = "series_",
    values_to = "series"
    )
```

## Check for completeness and correctness

``` r
missing_bakers_df <- bakers_df |>
  anti_join(bakes_df, by = c("baker", "series"))
```

There are 26 - 1(row for column names) = 25 missing bakers that do not
have the same information in bakes_df

``` r
  anti_join(bakers_df, bakes_df)
```

    ## Joining with `by = join_by(baker, series)`

    ## # A tibble: 26 × 6
    ##    baker  baker_last_name series baker_age baker_occupation             hometown
    ##    <chr>  <chr>            <dbl>     <dbl> <chr>                        <chr>   
    ##  1 Alice  Fevronia            10        28 Geography teacher            Essex   
    ##  2 Amelia LeBruin             10        24 Fashion designer             Halifax 
    ##  3 Antony Amourdoux            9        30 Banker                       London  
    ##  4 Briony Williams             9        33 Full-time parent             Bristol 
    ##  5 Dan    Beasley-Harling      9        36 Full-time parent             London  
    ##  6 Dan    Chambers            10        32 Support worker               Rotherh…
    ##  7 David  Atherton            10        36 International health adviser Whitby  
    ##  8 Helena Garcia              10        40 Online project manager       Leeds   
    ##  9 Henry  Bird                10        20 Student                      Durham  
    ## 10 Imelda McCarron             9        33 Countryside recreation offi… County …
    ## # ℹ 16 more rows

There are 25 missing bakers that do not have the same information in
bakes_df

``` r
anti_join(bakers_df, results_df)
```

    ## Joining with `by = join_by(baker, series)`

    ## # A tibble: 1 × 6
    ##   baker baker_last_name series baker_age baker_occupation hometown    
    ##   <chr> <chr>            <dbl>     <dbl> <chr>            <chr>       
    ## 1 Jo    Wheatley             2        41 Housewife        Ongar, Essex

Jo Wheatley is missing, it appears that in this is a nickname and her
full name is Joanne. Let’s fix this.

``` r
results_df <- results_df |> 
  mutate(baker = case_match(
         baker, "Joanne" ~ "Jo")
  )
```

### Merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders.

Left join to merge datasets

``` r
bakers_bakes_merge = 
  left_join(bakers_df, bakes_df, by = c("series", "baker")) 
```

Another merge, final merge

``` r
full_merge = 
  left_join(bakers_bakes_merge, results_df, by = c("series", "baker"))

write_csv(full_merge, "data/full_merge.csv")
```

Describe your data cleaning process, including any questions you have or
choices you made. Briefly discuss the final dataset.

This process was difficult. I still have a hard time understanding pivot
moves and why they are useful.

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10. Comment on this table – were there any
predictable overall winners? Any surprises?

``` r
star_baker_or_winner <- full_merge |>
  filter(
          result %in% c("STAR BAKER", "WINNER"),
          series %in% c(5:10) 
         ) |>
  select(series, baker, result) %>%
    arrange(series)
```

Difficulty with star baker and winner question. Move on to final
question.

Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?

Imported previously above. First rename columns in viewers_df

``` r
viewers_table <- viewers_df |>
  rename(viewers = series,
          series = series_number) |>
  mutate(series = as.double(series))
```

``` r
head(viewers_table, n = 10)
```

    ## # A tibble: 10 × 3
    ##    episode series viewers
    ##      <dbl>  <dbl>   <dbl>
    ##  1       1      1    2.24
    ##  2       1      2    3.1 
    ##  3       1      3    3.85
    ##  4       1      4    6.6 
    ##  5       1      5    8.51
    ##  6       1      6   11.6 
    ##  7       1      7   13.6 
    ##  8       1      8    9.46
    ##  9       1      9    9.55
    ## 10       1     10    9.62

What was the average viewership in Season 1 is 2.77.

The average viewership in Season 5 was 10.039.
